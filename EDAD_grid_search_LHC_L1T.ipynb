{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.signal import butter, filtfilt\n",
    "from sklearn.metrics import roc_curve\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "import h5py, numpy as np\n",
    "import os\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_dir = \"./figures\"\n",
    "data_dir = \"./data\"\n",
    "results_dir = \"./results\"\n",
    "\n",
    "os.makedirs(fig_dir, exist_ok=True)\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EDAD():\n",
    "\n",
    "    def __init__(self, lr, mom_score, mode, n_learning, device='cpu'):\n",
    "        self.lr = lr\n",
    "        self.mom_score = mom_score\n",
    "        self.mode = mode\n",
    "        self.n_learning = n_learning\n",
    "        self.device = device\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        device = self.device\n",
    "\n",
    "        X = torch.tensor(X, dtype=torch.float).to(device)\n",
    "        R = torch.eye(X.shape[1], dtype=torch.float).to(device)\n",
    "        self.p = (1.0) / (X.shape[1] - 1)\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        #  MODE: UNSUPERVISED ('u')\n",
    "        # ---------------------------------------------------------\n",
    "        if self.mode == 'u':\n",
    "\n",
    "            NR = torch.zeros(X.shape[0]).to(device)\n",
    "\n",
    "            for i in tqdm(range(X.shape[0]), desc=\"EDAD (unsupervised)\"):\n",
    "                XD = F.linear(X[i:i+1, :], R)\n",
    "                XD = (XD.T @ XD) / len(XD)\n",
    "                XD -= torch.diag(torch.diag(XD))\n",
    "                XD = (self.p * XD @ R)\n",
    "                XD = self.lr * XD\n",
    "                R -= XD\n",
    "                NR[i] = torch.norm(R)\n",
    "\n",
    "            NR = np.abs(np.gradient(NR.cpu()))\n",
    "            scores = np.zeros(len(NR))\n",
    "            scores[0] = NR[0]\n",
    "\n",
    "            for i in range(len(NR)):\n",
    "                scores[i] = (1 - self.mom_score) * scores[i - 1] + self.mom_score * NR[i]\n",
    "\n",
    "            decision_scores = torch.nan_to_num(torch.tensor(scores), nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "            self.decision_scores_ = decision_scores\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        #  MODE: SEMI-SUPERVISED ('s')\n",
    "        # ---------------------------------------------------------\n",
    "        elif self.mode == 's':\n",
    "\n",
    "            NR = torch.zeros(X.shape[0] - self.n_learning).to(device)\n",
    "\n",
    "            for i in tqdm(range(X.shape[0]), desc=\"EDAD (semi-supervised)\"):\n",
    "                XD = F.linear(X[i:i+1, :], R)\n",
    "                XD = (XD.T @ XD) / len(XD)\n",
    "                XD -= torch.diag(torch.diag(XD))\n",
    "                XD = (self.p * XD @ R)\n",
    "\n",
    "                if i > self.n_learning - 1:\n",
    "                    NR[i - self.n_learning] = torch.mean(XD)\n",
    "                else:\n",
    "                    R -= (self.lr * XD)\n",
    "                    if i == self.n_learning - 1:\n",
    "                        print(\"Stopping R updates at step\", i)\n",
    "\n",
    "            self.decision_scores_ = NR\n",
    "        else:\n",
    "\n",
    "            NR = torch.zeros(X.shape[0]).to(device)\n",
    "\n",
    "            for i in tqdm(range(X.shape[0]), desc=\"EDAD (unsupervised)\"):\n",
    "                XD = F.linear(X[i:i+1, :], R)\n",
    "                XD = (XD.T @ XD) / len(XD)\n",
    "                XD -= torch.diag(torch.diag(XD))\n",
    "                XD = (self.p * XD @ R)\n",
    "                XD = self.lr * XD\n",
    "                R -= XD\n",
    "\n",
    "            self.decorr_energy = R\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading LHC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background shape:  (4000000, 57)\n",
      "Signal1 shape:  (340544, 57)\n",
      "Signal2 shape:  (55969, 57)\n",
      "Signal3 shape:  (691283, 57)\n",
      "Signal4 shape:  (760272, 57)\n"
     ]
    }
   ],
   "source": [
    "def load_events(path):\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        X = f[\"Particles\"][...]\n",
    "    return X\n",
    "\n",
    "\n",
    "X_bg  = load_events(os.path.join(data_dir, \"background_for_training.h5\"))\n",
    "X_bg = X_bg[:, :, :-1].reshape(X_bg.shape[0], -1)\n",
    "\n",
    "X_sig1 = load_events(os.path.join(data_dir, \"leptoquark_LOWMASS_lepFilter_13TeV.h5\"))\n",
    "X_sig1 = X_sig1[:, :, :-1].reshape(X_sig1.shape[0], -1)\n",
    "\n",
    "X_sig2 = load_events(os.path.join(data_dir, \"Ato4l_lepFilter_13TeV.h5\"))\n",
    "X_sig2 = X_sig2[:, :, :-1].reshape(X_sig2.shape[0], -1)\n",
    "\n",
    "X_sig3 = load_events(os.path.join(data_dir, \"hToTauTau_13TeV_PU20.h5\")) \n",
    "X_sig3 = X_sig3[:, :, :-1].reshape(X_sig3.shape[0], -1)\n",
    "\n",
    "X_sig4 = load_events(os.path.join(data_dir, \"hChToTauNu_13TeV_PU20.h5\"))\n",
    "X_sig4 = X_sig4[:, :, :-1].reshape(X_sig4.shape[0], -1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Background shape: \", X_bg.shape)\n",
    "print(\"Signal1 shape: \", X_sig1.shape)\n",
    "print(\"Signal2 shape: \", X_sig2.shape)\n",
    "print(\"Signal3 shape: \", X_sig3.shape)\n",
    "print(\"Signal4 shape: \", X_sig4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a randomly selected training window of train_length = 80,000 samples (≈2% of the total 4M samples) as a small background slice for grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_length = 80000\n",
    "\n",
    "# X_bg_train, X_bg_test = train_test_split(\n",
    "#     X_bg, \n",
    "#     train_size=train_length, \n",
    "#     # test_size=80000, \n",
    "#     shuffle=True, \n",
    "#     random_state=None\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train and test splits\n",
    "# np.save(os.path.join(data_dir,\"LHC_L1T_X_bg_train.npy\"), X_bg_train)\n",
    "# np.save(os.path.join(data_dir,\"LHC_L1T_X_bg_test.npy\"), X_bg_test)\n",
    "\n",
    "# load train and test splits\n",
    "X_bg_train = np.load(os.path.join(data_dir,\"LHC_L1T_X_bg_train.npy\"))\n",
    "X_bg_test = np.load(os.path.join(data_dir,\"LHC_L1T_X_bg_test.npy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EDAD (unsupervised):   0%|          | 0/80000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EDAD (unsupervised): 100%|██████████| 80000/80000 [00:08<00:00, 9412.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best learning rate found: 8e-06 with diffence: tensor(2368.2937)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EDAD (unsupervised): 100%|██████████| 80000/80000 [00:08<00:00, 9312.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best learning rate found: 2e-06 with diffence: tensor(2347.0867)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EDAD (unsupervised): 100%|██████████| 80000/80000 [00:08<00:00, 9457.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best learning rate found: 8e-07 with diffence: tensor(2196.2815)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EDAD (unsupervised): 100%|██████████| 80000/80000 [00:08<00:00, 9410.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best learning rate found: 2e-07 with diffence: tensor(1966.4988)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EDAD (unsupervised): 100%|██████████| 80000/80000 [00:08<00:00, 9429.70it/s]\n",
      "EDAD (unsupervised): 100%|██████████| 80000/80000 [00:08<00:00, 9446.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best learning rate is: 2e-07 with diffence: tensor(1966.4988)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate_list = [8e-6, 2e-6, 8e-7, 2e-7, 8e-8, 2e-8]\n",
    "\n",
    "best_lr = None\n",
    "min_diff = 1e9\n",
    "\n",
    "for learning_rate in learning_rate_list:\n",
    "\n",
    "    EDAD_model = EDAD(lr=learning_rate, mom_score=0.25, mode='e', n_learning=train_length, device=\"cpu\")\n",
    "\n",
    "    EDAD_model.fit(X_bg_train)\n",
    "    Decorrelation_transform = EDAD_model.decorr_energy\n",
    "\n",
    "    X_bg_train_tensor = torch.tensor(X_bg_train[len(X_bg_train)//2:], dtype=torch.float)\n",
    "    corr_matrix_bg = (X_bg_train_tensor.T @ X_bg_train_tensor) / len(X_bg_train_tensor)\n",
    "    corr_matrix_bg -= torch.diag(torch.diag(corr_matrix_bg))\n",
    "    corr_matrix_bg = corr_matrix_bg @ Decorrelation_transform\n",
    "\n",
    "    diff = torch.norm(corr_matrix_bg)\n",
    "\n",
    "    if diff < min_diff:\n",
    "        min_diff = diff\n",
    "        best_lr = learning_rate\n",
    "        print(\"New best learning rate found:\", best_lr, \"with diffence:\", min_diff)\n",
    "\n",
    "print(\"Best learning rate is:\", best_lr, \"with diffence:\", min_diff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
